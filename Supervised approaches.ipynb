{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-building phase: supervised approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from prep import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In preprocessing the data we make use of the *prep* function, which simultaneously allows us both to deal with the missing values, giving us the choice of removing them, or partially removing them by replacing the remainder with the mean or median of the corresponding variable, and to scale the data, with the possibility of choosing the method by which to scale such data from all the scalers in scikit-learn, by default the MinMaxScaler is set. The function then takes as input a pandas DataFrame and outputs a numpy ndarray containing the cleaned data from the previous dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our idea is to generate two datasets: the first by eliminating all observations having at least one component with a missing value, the second by eliminating only 50 percent of those observations. Eventually we will train each model using both datasets and collect their metrics in order to assess whether on average such a reduction in missing values to be eliminated (thus replacing the missing part) resulted in any benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset size:  (3276, 10) - type:  <class 'pandas.core.frame.DataFrame'>\n",
      "cleaned dataset with all of missing values removed:  (2011, 10) - type:  <class 'numpy.ndarray'>\n",
      "cleaned dataset with 50% of missing values removed:  (2515, 10) - type:  <class 'numpy.ndarray'>\n",
      "cleaned dataset with 100% of missing values removed:  (2993, 10) - type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "random.seed(13)\n",
    "water = pd.read_csv('dataset/drinking_water_potability.csv')\n",
    "water0 = prep( \n",
    "    df = water,\n",
    "    axis='obs',\n",
    "    perc=100,\n",
    "    fill_method='mean',\n",
    "    scaler= preprocessing.MinMaxScaler()\n",
    "    )\n",
    "water50 = prep(\n",
    "    df = water,\n",
    "    axis='obs',\n",
    "    perc=50,\n",
    "    fill_method='mean',\n",
    "    scaler= preprocessing.MinMaxScaler()\n",
    ")\n",
    "water100 = prep(\n",
    "    df = water,\n",
    "    axis='obs',\n",
    "    perc=0,\n",
    "    fill_method='mean',\n",
    "    scaler= preprocessing.MinMaxScaler()\n",
    ")\n",
    "print('original dataset size: ', water.shape, '- type: ', type(water))\n",
    "print('cleaned dataset with all of missing values removed: ', np.shape(water0), '- type: ', type(water0))\n",
    "print('cleaned dataset with 50% of missing values removed: ', np.shape(water50), '- type: ', type(water50))\n",
    "print('cleaned dataset with 100% of missing values removed: ', np.shape(water100), '- type: ', type(water100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we proceed to divide the dataset into train set, validation set and test set. To do this, we make use of the *train_test_split()* function of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE SPLITTING: \n",
      "\n",
      "X_water0 shape:  (2011, 8)\n",
      "y_water0 shape:  (2011,)\n",
      "\n",
      "AFTER SPLITTING: \n",
      "X_train0 shape:  (1206, 8)\n",
      "X_val0 shape:  (402, 8)\n",
      "X_test0 shape:  (403, 8)\n",
      "y_train0 shape:  (1206,)\n",
      "y_val0 shape:  (402,)\n",
      "y_test0 shape:  (403,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,X_val, X_test, y_val, y_test=splitting_func(water0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE SPLITTING: \n",
      "\n",
      "X_water0 shape:  (2515, 8)\n",
      "y_water0 shape:  (2515,)\n",
      "\n",
      "AFTER SPLITTING: \n",
      "X_train0 shape:  (1509, 8)\n",
      "X_val0 shape:  (503, 8)\n",
      "X_test0 shape:  (503, 8)\n",
      "y_train0 shape:  (1509,)\n",
      "y_val0 shape:  (503,)\n",
      "y_test0 shape:  (503,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,X_val, X_test, y_val, y_test=splitting_func(water50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE SPLITTING: \n",
      "\n",
      "X_water0 shape:  (2993, 8)\n",
      "y_water0 shape:  (2993,)\n",
      "\n",
      "AFTER SPLITTING: \n",
      "X_train0 shape:  (1795, 8)\n",
      "X_val0 shape:  (599, 8)\n",
      "X_test0 shape:  (599, 8)\n",
      "y_train0 shape:  (1795,)\n",
      "y_val0 shape:  (599,)\n",
      "y_test0 shape:  (599,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,X_val, X_test, y_val, y_test=splitting_func(water100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
